---
title: "Impulse Responses and Auralization"
publishDate: "2024-06-23"
cover: "/images/blog/impulse-responses-and-auralization/cover.png"
tags: []
---# Impulse Responses and Auralization

*   Jun 23, 2024
*   2 min read

![](/images/blog/impulse-responses-and-auralization/image-1.webp)

![](/images/blog/impulse-responses-and-auralization/image-3.webp)

![](/images/blog/impulse-responses-and-auralization/image-5.webp)

#pro-gallery-34ji514393-not-scoped .gallery-item-hover::before { background: transparent !important}

try { window.requestAnimationFrame(function() { var ele = document.getElementById('pro-gallery-34ji514393-not-scoped'); var pgMeasures = ele.getBoundingClientRect(); var options = (() => "gallerySizeType:px|enableInfiniteScroll:true|titlePlacement:SHOW\_ON\_HOVER|imageMargin:5|isVertical:false|gridStyle:0|galleryLayout:1|numberOfImagesPerRow:0|gallerySizePx:300|cubeType:fill|galleryThumbnailsAlignment:none")(ele); var width = pgMeasures.width; var height = pgMeasures.height; var isIOS = /iPad|iPhone|iPod/.test(navigator?.userAgent); if(isIOS) { width = width; width = width; height = height; height = height; } else { width = width; width = width; height = height; height = height; } pgMeasures = { top: pgMeasures.top, width, height }; var isVertical = options.includes('layoutParams\_structure\_scrollDirection:"VERTICAL"'); var layoutFixerUrl = '/\_serverless/pro-gallery-css-v4-server/layoutCss?ver=2&id=34ji514393-not-scoped&items=3545\_1080\_1350|3408\_933\_509|3727\_944\_529&container=' + pgMeasures.top + '\_' + pgMeasures.width + '\_' + pgMeasures.height + '\_' + window.innerHeight + '&options=' + options; document.getElementById('layout-fixer-style-34ji514393-not-scoped').setAttribute('href', encodeURI(layoutFixerUrl)); }); } catch (e) { console.warn('Cannot set layoutFixer css', e); }

How to record the acoustic characteristics of a space?

Whereas, in the past, I focused on field recording and sampling (of environmental sounds) as the source of sound worlds and compositional ideas, when viewing the world as an orchestra of echoes, the natural progression is to record impulse responses (IRs), also termed acoustic fingerprints and use these as (meta) compositional process and/or material.

An impulse such as a starter pistol, balloon pop or frequency sweep is used to stimulate the acoustics of a space. The reply contains an acoustic fingerprint of that source-listener spatial relationship with its values of frequency and resonance responses. It is also possible to completely simulate such IRs mathematically from visual information. The IR information is the equivalent of a 3d digital visual model of space but for sound. Through convolution, incoming audio signal can be convolved with the response of a space, thus placing us in a simulated acoustic virtual reality copy of that space.

As composers, we can create recombinant sonic architectures based on places that morph into each other or are juxtaposed next to each other.  We can sing into a hybrid skyscraper-duomo-temple-tunnel that morphs into a mineshaft-silo-subway-staircase. We can go sonically where the cinematic eye has taken us. Via forensic acoustics, we can reverse engineer sound recordings from the past to use clips with footsteps to find the IRs of places from film scenes. We can try discovering what acoustic landscapes are revealed by lightning thunderclaps. We can go underwater to include underwater echoes.  We can burry Echo underground in a tiny box, consider miniature and micro spaces, transpose a sound file, record the echo, and transpose it back to the original. 

The source positions are where the loudspeaker will be positioned and correspond to parts of the space in which natural or artificial sources are present. The receiver positions correspond to listener positions. An impulse response is captured for every source-receiver combination, allowing for a full acoustic mapping of each space. In the context of intangible heritage, virtual reconstructions of world heritage sites are becoming increasingly useful to allow for multi-sensory immersive access, research and conservation.

For a technical overview of IRs, convolution reverb and auralisation (terms frequently used in this chapter) see Jens Holger Rindel, Claus Lynge Christensen, and George Koutsouris, "Simulations, Measurements and Auralisations in Architectural Acoustics," in _Proceedings of the Acoustics_ (2013); or F. Rumsey, “Spatial Audio.” Focal Press, 2012; or Huseyin Hacihabiboglu, Enzo De Sena, Zoran Cvetkovic, James Johnston, and Julius O. Smith III, "Perceptual Spatial Audio Recording, Simulation, and Rendering: An Overview of Spatial-Audio Techniques Based on Psychoacoustics," _IEEE Signal Processing Magazine_ 34, no. 3 (2017): 36-54.

Tags:

*   [echo](https://chienpien.wixsite.com/fakeland/blog/tags/echo)
*   [immersivelistening](https://chienpien.wixsite.com/fakeland/blog/tags/immersivelistening)
*   [acousticatlas](https://chienpien.wixsite.com/fakeland/blog/tags/acousticatlas)
*   [impulseresponse](https://chienpien.wixsite.com/fakeland/blog/tags/impulseresponse)
*   [acoustics](https://chienpien.wixsite.com/fakeland/blog/tags/acoustics)

44

44 views

0

0 comments

Post not marked as liked
